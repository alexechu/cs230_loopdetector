{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Train a ConvNet\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, LeakyReLU, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_modelD(X_train, Y_train, X_dev, Y_dev, learning_rate=0.0001, num_epochs=100, batch_size=32, print_cost=True):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(7, 7), padding='same', activation='relu', input_shape=(64,64,1)))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(128, kernel_size=(4, 4), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(4, 4), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(512, kernel_size=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(512, kernel_size=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    \n",
    "    # Flatten and Fully Connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    \n",
    "    # Compile and train\n",
    "    model.compile(optimizer=optimizers.SGD(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_dev, Y_dev), epochs=num_epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def train_model(X_train, Y_train, X_dev, Y_dev, learning_rate=0.0001, num_epochs=100, batch_size=32, print_cost=True):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(4, 4), strides=2, padding='same', input_shape=(64,64,1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, kernel_size=(4, 4), strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Flatten and Fully Connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    \n",
    "    # Compile and train\n",
    "    model.compile(optimizer=optimizers.SGD(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_dev, Y_dev), epochs=num_epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & train small data\n",
    "\n",
    "# print('Loading data...')\n",
    "# strain_x = np.moveaxis(np.load('../small_data/small_train_x.npy'), -1, 0)\n",
    "# strain_y = np.moveaxis(np.load('../small_data/small_train_y.npy'), -1, 0)\n",
    "# sdev_x = np.moveaxis(np.load('../small_data/small_dev_x.npy'), -1, 0)\n",
    "# sdev_y = np.moveaxis(np.load('../small_data/small_dev_y.npy'), -1, 0)\n",
    "# stest_x = np.moveaxis(np.load('../small_data/small_test_x.npy'), -1, 0)\n",
    "# stest_y = np.moveaxis(np.load('../small_data/small_test_y.npy'), -1, 0)\n",
    "# strain_x = np.expand_dims(strain_x, axis=-1)\n",
    "# strain_y = np.reshape(strain_y, (strain_y.shape[0], strain_y.shape[1]))\n",
    "# sdev_x = np.expand_dims(sdev_x, axis=-1)\n",
    "# sdev_y = np.reshape(sdev_y, (sdev_y.shape[0], sdev_y.shape[1]))\n",
    "# stest_x = np.expand_dims(stest_x, axis=-1)\n",
    "# stest_y = np.reshape(stest_y, (stest_y.shape[0], stest_y.shape[1]))\n",
    "\n",
    "# print('Beginning training...')\n",
    "# smodel, shistory = train_model(strain_x, strain_y, sdev_x, sdev_y, num_epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(178800, 64, 64, 1)\n",
      "(22350, 64)\n",
      "Data loaded...\n"
     ]
    }
   ],
   "source": [
    "# Load full data\n",
    "\n",
    "print('Loading data...')\n",
    "train_x = np.moveaxis(np.load('/data/loop_detector/train_X.npy'), -1, 0)\n",
    "train_y = np.moveaxis(np.load('/data/loop_detector/train_Y.npy'), -1, 0)\n",
    "dev_x = np.moveaxis(np.load('/data/loop_detector/dev_X.npy'), -1, 0)\n",
    "dev_y = np.moveaxis(np.load('/data/loop_detector/dev_Y.npy'), -1, 0)\n",
    "test_x = np.moveaxis(np.load('/data/loop_detector/test_X.npy'), -1, 0)\n",
    "test_y = np.moveaxis(np.load('/data/loop_detector/test_Y.npy'), -1, 0)\n",
    "\n",
    "trainx = np.expand_dims(train_x, axis=-1)\n",
    "trainy = np.reshape(train_y, (train_y.shape[0], train_y.shape[1]))\n",
    "devx = np.expand_dims(dev_x, axis=-1)\n",
    "devy = np.reshape(dev_y, (dev_y.shape[0], dev_y.shape[1]))\n",
    "testx = np.expand_dims(test_x, axis=-1)\n",
    "testy = np.reshape(test_y, (test_y.shape[0], test_y.shape[1]))\n",
    "print(trainx.shape)\n",
    "print(testy.shape)\n",
    "print('Data loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 178800 samples, validate on 22350 samples\n",
      "Epoch 1/5\n",
      "178800/178800 [==============================] - 254s 1ms/step - loss: 0.6796 - acc: 0.5761 - val_loss: 0.6721 - val_acc: 0.5911\n",
      "Epoch 2/5\n",
      "178800/178800 [==============================] - 253s 1ms/step - loss: 0.6674 - acc: 0.5937 - val_loss: 0.6616 - val_acc: 0.6002\n",
      "Epoch 3/5\n",
      "178800/178800 [==============================] - 253s 1ms/step - loss: 0.6526 - acc: 0.6166 - val_loss: 0.6443 - val_acc: 0.6300\n",
      "Epoch 4/5\n",
      "178800/178800 [==============================] - 253s 1ms/step - loss: 0.6338 - acc: 0.6437 - val_loss: 0.6256 - val_acc: 0.6523\n",
      "Epoch 5/5\n",
      "178800/178800 [==============================] - 253s 1ms/step - loss: 0.6171 - acc: 0.6626 - val_loss: 0.6113 - val_acc: 0.6679\n"
     ]
    }
   ],
   "source": [
    "# Train full data\n",
    "\n",
    "print('Beginning training...')\n",
    "lr = 0.001\n",
    "nepochs = 5\n",
    "mbsize = 32\n",
    "model, history = train_modelD(trainx, trainy, devx, devy, learning_rate=lr, num_epochs=nepochs, batch_size=mbsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "\n",
    "my_model = model\n",
    "x = trainx\n",
    "y = trainy\n",
    "\n",
    "i = np.random.choice(range(x.shape[0]))\n",
    "print(str(i) + 'th example')\n",
    "pred = np.round(my_model.predict(x[i].reshape(1,64,64,1)).reshape(64,1))\n",
    "label = y[i].reshape(64,1)\n",
    "results = np.concatenate((pred, label, (pred-label)*99, (pred+label-1)*100), axis=1)\n",
    "print('Pred   True   FP/FN    TP/TN')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random((64,64,1))[np.newaxis,...]\n",
    "test = trainx[0][np.newaxis,...]\n",
    "layer_outs = [func([test, 1.]) for func in functors]\n",
    "print(layer_outs[7][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "model.save('modelD.h5'.format(lr, nepochs, mbsize))\n",
    "with open('historyD.pkl'.format(lr, nepochs, mbsize), 'wb') as f:\n",
    "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
